{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import os, json\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib as mpl\n",
    "%matplotlib inline \n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.tree import export_graphviz \n",
    "import graphviz\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from os import path\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mOptioanl categories:\u001b[0m ['food', 'art', 'publishing', 'comics', 'journalism', 'crafts', 'design', 'film & video', 'dance', 'photography', 'technology', 'music', 'games', 'fashion', 'theater']\n",
      "Select your category: crafts\n",
      "16    crafts\n",
      "Name: category.slug, dtype: object\n",
      "\u001b[1mCategory is OK\u001b[0m\n",
      "Enter your campaign name: Design a new Table\n",
      "Enter your campaign description: Fantastic new table design very trendy\n",
      "\n",
      "\n",
      "\u001b[1mProject category: \u001b[0m crafts\n",
      "\u001b[1mProject Name: \u001b[0m Design a new Table\n",
      "\u001b[1mProject Description: \u001b[0m Fantastic new table design very trendy\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv('data/bdata.csv') \n",
    "data=data.drop(['Unnamed: 0'],axis=1)\n",
    "\n",
    "\n",
    "cats=list(data['category.slug'].unique())\n",
    "print('\\033[1m'+'Optioanl categories:'+'\\033[0m',cats)\n",
    "\n",
    "cat_select=''\n",
    "while cat_select not in cats:\n",
    "    cat_select=input('\\033[1m'+'Select your category: '+'\\033[0m')\n",
    "else:\n",
    "        data=data.loc[data['category.slug']==cat_select]\n",
    "        print(data['category.slug'][:1])\n",
    "        print ('\\033[1m'+'Category is OK'+'\\033[0m')\n",
    "name=input ('\\033[1m'+'Enter your campaign name: '+'\\033[0m')\n",
    "blurb=input ('\\033[1m'+'Enter your campaign description: '+'\\033[0m')\n",
    "print('\\n')\n",
    "print('\\033[1m'+'Project category: '+'\\033[0m',cat_select)\n",
    "print('\\033[1m'+'Project Name: '+'\\033[0m',name)\n",
    "print('\\033[1m'+'Project Description: '+'\\033[0m',blurb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name and Description improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good words for name: ['david', 'magnetic', 'bowlmaker', 'eagle', 'good', 'whiskey', 'inspired', 'ltd', 'press', 'yarns', 'oils', 'walsh', 'quilt', 'razors', 'wick', 'n', 'oil', 'book', 'limited', 'fine', 'ceramic', 'pattern', 'exotic', 'holiday', 'accessories', 'bowls', 'cat', 'stationery', 'fire', 'turned', 'oak', 'bourbon', 'veterans', 'knitted', 'barrel', 'kids', 'trees', 'scottish', 'kiln', 'games', 'expansion', 'sustainable', 'leather', 'dyed', 'pen', 'ceramics', 'card', 'fiber', 'day', 'little', 'system', 'edition', 'real', 'black', 'ancient', 'writing']\n",
      "\n",
      "Bad words for name: ['need', 'old', 'd', 'at', 'get', 'free', 'business', 'dog', 'skin', 'pet', 'guitars', 'cutting', 'our', 'personalized', 'suspended', 't', 'beauty', 'store', 'rustic', 'soaps', 'soap', 'bath', 'can', 'tree', 'friendly', 'decor', 'time', 'dream', 'fun', 'stand', 'embroidery', 'crafting', 'bottle', 'laser', 'boutique', 'scented', 'tiny', 'reclaimed', 'american', 'items', 'scents', 'm', 'wax', 'fund', 'jewelry', 'homemade', 'creative', 'eco', 'children', 'blankets', 'house', 'furniture', 'beautiful', 'signs', 'organic', 'building']\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "words = data[data.state == 'successful']['name']\n",
    "words=words.values\n",
    "import re\n",
    "words=words.tolist()\n",
    "words[1]\n",
    "words=str(words)\n",
    "num=[int(s) for s in words.split() if s.isdigit()]\n",
    "\n",
    "words = data[data.state == 'successful']['name']\n",
    "words=words.apply(lambda x: x.lower())\n",
    "words=list(filter(lambda x:x, map(lambda x:re.sub(r'[^A-Za-z]', ' ', x), words)))\n",
    "\n",
    "words=str(words).split(\" \")\n",
    "words=list(filter(lambda x:x, map(lambda x:re.sub(r'[^A-Za-z]',\"\", x), words)))\n",
    "\n",
    "words.append([num])\n",
    "\n",
    "words= str(words)\n",
    "words=words.replace(' ','')\n",
    "words=words.replace(\"'\",'')\n",
    "words=words.split(sep=',')\n",
    "\n",
    "s_counter = collections.Counter(words)\n",
    "a=s_counter.most_common(n=150)\n",
    "dfgwords=pd.DataFrame(a,columns=['word','freq'])\n",
    "a = [x[0] for x in a]\n",
    "dfgwords\n",
    "\n",
    "words = data[data.state == 'failed']['name']\n",
    "words=words.values\n",
    "import re\n",
    "words=words.tolist()\n",
    "words[1]\n",
    "words=str(words)\n",
    "num=[int(s) for s in words.split() if s.isdigit()]\n",
    "\n",
    "words = data[data.state == 'failed']['name']\n",
    "words=words.apply(lambda x: x.lower())\n",
    "words=list(filter(lambda x:x, map(lambda x:re.sub(r'[^A-Za-z]', ' ', x), words)))\n",
    "\n",
    "words=str(words).split(\" \")\n",
    "words=list(filter(lambda x:x, map(lambda x:re.sub(r'[^A-Za-z]',\"\", x), words)))\n",
    "\n",
    "words.append([num])\n",
    "\n",
    "words= str(words)\n",
    "words=words.replace(' ','')\n",
    "words=words.replace(\"'\",'')\n",
    "words=words.split(sep=',')\n",
    "\n",
    "f_counter = collections.Counter(words)\n",
    "b=f_counter.most_common(n=150)\n",
    "dfbwords=pd.DataFrame(b,columns=['word','freq'])\n",
    "b = [x[0] for x in b]\n",
    "\n",
    "\n",
    "#just the uniqe words\n",
    "s_words=list(set(a) - set(b))\n",
    "f_words=list(set(b) - set(a))\n",
    "wordsT=pd.DataFrame()\n",
    "wordsT['suc_w']=list(set(a) - set(b))\n",
    "wordsT['fail_w']=list(set(b) - set(a))\n",
    "wordsT['c']=1\n",
    "print('Good words for name:', s_words)\n",
    "print()\n",
    "print('Bad words for name:',f_words)\n",
    "\n",
    "def show_wordcloud(wordsT, title = None):\n",
    "    '''Split names by space and generate word counts.'''\n",
    "    wordcloud = WordCloud(\n",
    "        background_color='white',\n",
    "        max_words=150,\n",
    "        max_font_size=40, \n",
    "        scale=3,\n",
    "        random_state=1 \n",
    "    ).generate(str(wordsT))\n",
    "\n",
    "    fig = plt.figure(1, figsize=(12, 12))\n",
    "    plt.axis('off')\n",
    "    if title: \n",
    "        fig.suptitle(title, fontsize=20)\n",
    "        fig.subplots_adjust(top=2.3)\n",
    "\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.show()\n",
    "\n",
    "#show_wordcloud(wordsT[wordsT.c == 1]['suc_w'])\n",
    "#show_wordcloud(wordsT[wordsT.c == 1]['fail_w'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good words for description: ['two', 'based', 'kickstarter', 'set', 'pottery', 'good', 'better', 'space', 'most', 'beard', 'favorite', 'patterns', 'domestic', 'book', 'working', 'limited', 'yarn', 'fine', 'her', 'through', 'raise', 'exotic', 'studio', 'support', 'collection', 'bowls', 'raising', 'perfect', 'paper', 'turned', 'brand', 'years', 'greeting', 'friends', 'barrels', 'woods', 'range', 'kiln', 'reclaimed', 'women', 'year', 'christmas', 'knitting', 'sustainable', 'dyed', 'turn', 'pen', 'fund', 'card', 'fiber', 'little', 'grow', 'funds', 'keep', 'woodworking']\n",
      "\n",
      "Bad words for description: ['crafts', 'family', 'people', 'baby', 'projects', 'well', 'give', 'many', 'everyone', 'provide', 'skin', 'open', 'those', 'crochet', 'store', 'about', 'created', 'come', 'been', 'only', 'starting', 'r', 'soaps', 'pieces', 'different', 'bath', 'look', 'gift', 'friendly', 'decor', 'back', 'dream', 'not', 'supplies', 'where', 'scented', 'trying', 'kids', 'sell', 'company', 'machine', 'started', 'boards', 'items', 'needs', 'scents', 'what', 'jewelry', 'homemade', 'affordable', 'children', 'over', 'furniture', 'de', 'care']\n"
     ]
    }
   ],
   "source": [
    "words = data[data.state == 'successful']['blurb']\n",
    "words=words.values\n",
    "import re\n",
    "words=words.tolist()\n",
    "words[1]\n",
    "words=str(words)\n",
    "num=[int(s) for s in words.split() if s.isdigit()]\n",
    "\n",
    "words = data[data.state == 'successful']['blurb']\n",
    "words=words.apply(lambda x: x.lower())\n",
    "words=list(filter(lambda x:x, map(lambda x:re.sub(r'[^A-Za-z]', ' ', x), words)))\n",
    "\n",
    "words=str(words).split(\" \")\n",
    "words=list(filter(lambda x:x, map(lambda x:re.sub(r'[^A-Za-z]',\"\", x), words)))\n",
    "\n",
    "words.append([num])\n",
    "\n",
    "words= str(words)\n",
    "words=words.replace(' ','')\n",
    "words=words.replace(\"'\",'')\n",
    "words=words.split(sep=',')\n",
    "\n",
    "s_counter = collections.Counter(words)\n",
    "a=s_counter.most_common(n=200)\n",
    "dfgblurb=pd.DataFrame(a,columns=['word','freq'])\n",
    "a = [x[0] for x in a]\n",
    "a\n",
    "\n",
    "words = data[data.state == 'failed']['blurb']\n",
    "words=words.values\n",
    "import re\n",
    "words=words.tolist()\n",
    "words[1]\n",
    "words=str(words)\n",
    "num=[int(s) for s in words.split() if s.isdigit()]\n",
    "\n",
    "words = data[data.state == 'failed']['blurb']\n",
    "words=words.apply(lambda x: x.lower())\n",
    "words=list(filter(lambda x:x, map(lambda x:re.sub(r'[^A-Za-z]', ' ', x), words)))\n",
    "\n",
    "words=str(words).split(\" \")\n",
    "words=list(filter(lambda x:x, map(lambda x:re.sub(r'[^A-Za-z]',\"\", x), words)))\n",
    "\n",
    "words.append([num])\n",
    "\n",
    "words= str(words)\n",
    "words=words.replace(' ','')\n",
    "words=words.replace(\"'\",'')\n",
    "words=words.split(sep=',')\n",
    "\n",
    "b_counter = collections.Counter(words)\n",
    "b=b_counter.most_common(n=200)\n",
    "dfbblurb=pd.DataFrame(b,columns=['word','freq'])\n",
    "b = [x[0] for x in b]\n",
    "b\n",
    "\n",
    "#just the uniqe words\n",
    "s_blurb=list(set(a) - set(b))\n",
    "f_blurb=list(set(b) - set(a))\n",
    "wordsB=pd.DataFrame()\n",
    "wordsB['suc_b']=list(set(a) - set(b))\n",
    "wordsB['fail_b']=list(set(b) - set(a))\n",
    "wordsB['c']=1\n",
    "print('Good words for description:',s_blurb)\n",
    "print()\n",
    "print('Bad words for description:',f_blurb)\n",
    "\n",
    "def show_wordcloud(wordsB, title = None):\n",
    "    '''Split names by space and generate word counts.'''\n",
    "    wordcloud = WordCloud(\n",
    "        background_color='white',\n",
    "        max_words=100,\n",
    "        max_font_size=40, \n",
    "        scale=3,\n",
    "        random_state=1 # chosen at random by flipping a coin it was heads\n",
    "    ).generate(str(wordsB))\n",
    "\n",
    "    fig = plt.figure(1, figsize=(12, 12))\n",
    "    plt.axis('off')\n",
    "    if title: \n",
    "        fig.suptitle(title, fontsize=20)\n",
    "        fig.subplots_adjust(top=2.3)\n",
    "\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.show()\n",
    "#show_wordcloud(wordsB[wordsB.c == 1]['suc_b'])\n",
    "#show_wordcloud(wordsB[wordsB.c == 1]['fail_b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def goodblurb(s):\n",
    "    s = str(s)\n",
    "    s = re.sub(r'[^A-Za-z]', ' ', s)\n",
    "    s= s.lower()\n",
    "    s= s.split()\n",
    "    a=0\n",
    "    for i in s_blurb:\n",
    "        if i in s:\n",
    "            a+=1\n",
    "    return (a)\n",
    "\n",
    "data['goodblurb'] = data.blurb.apply(goodblurb)\n",
    "def badblurb(s):\n",
    "    s = str(s)\n",
    "    s = re.sub(r'[^A-Za-z]', ' ', s)\n",
    "    s= s.lower()\n",
    "    s= s.split()\n",
    "    a=0\n",
    "    for i in f_blurb:\n",
    "        if i in s:\n",
    "            a+=1\n",
    "    return (a)\n",
    "\n",
    "data['badblurb'] = data.blurb.apply(badblurb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def goodname(s):\n",
    "    s = str(s)\n",
    "    s = re.sub(r'[^A-Za-z]', ' ', s)\n",
    "    s= s.lower()\n",
    "    s= s.split()\n",
    "    a=0\n",
    "    for i in s_words:\n",
    "        if i in s:\n",
    "            a+=1\n",
    "    return (a)\n",
    "\n",
    "data['goodname'] = data.name.apply(goodname)\n",
    "\n",
    "def badname(s):\n",
    "    s = str(s)\n",
    "    s = re.sub(r'[^A-Za-z]', ' ', s)\n",
    "    s= s.lower()\n",
    "    s= s.split()\n",
    "    a=0\n",
    "    for i in f_words:\n",
    "        if i in s:\n",
    "            a+=1\n",
    "    return (a)\n",
    "\n",
    "data['badname'] = data.name.apply(badname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['goodname_mean']=data['goodname'].mean()\n",
    "data['goodname_corr']=data['goodname'].corr(data['state_num'])\n",
    "data['badname_mean']=data['badname'].mean()\n",
    "data['badname_corr']=data['badname'].corr(data['state_num'])\n",
    "data['goodblurb_mean']=data['goodblurb'].mean()\n",
    "data['goodblurb_corr']=data['goodblurb'].corr(data['state_num'])\n",
    "data['badblurb_mean']=data['badblurb'].mean()\n",
    "data['badblurb_corr']=data['badblurb'].corr(data['state_num'])\n",
    "\n",
    "data['goodname_score']=((data['goodname']-data['goodname_mean'])/data['goodname_mean'])*data['goodname_corr']\n",
    "data['badname_score']=((data['badname']-data['badname_mean'])/data['badname_mean'])*data['badname_corr']\n",
    "data['goodblurb_score']=((data['goodblurb']-data['goodblurb_mean'])/data['goodblurb_mean'])*data['goodblurb_corr']\n",
    "data['badblurb_score']=((data['badblurb']-data['badblurb_mean'])/data['badblurb_mean'])*data['badblurb_corr']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(data, open(\"odata.dat\", \"wb\")) # wb = write binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open(\"odata.dat\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word=data[['state_num','name_len','name_is_question',\n",
    "           'name_is_exclamation','name_is_upper','name_non_character',\n",
    "           'name_number_of_word','name_vowel_ratio','blurb_number_of_word',\n",
    "           'blurb_vowel_ratio','blurb_non_character','goodname','badname','goodblurb','badblurb']]\n",
    "corr_word=word.corr()\n",
    "corr_word=corr_word.loc['state_num']\n",
    "corr_word.nlargest(17)\n",
    "\n",
    "corr_word_re=corr_word.values.reshape(1,15)\n",
    "\n",
    "corr_t=pd.DataFrame(data=corr_word_re,columns=corr_word.index)\n",
    "corr_t.rename(columns=lambda x: x+'_corr', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_m=word\n",
    "word_m=word_m.mean()\n",
    "corr_mean_re=word_m.values.reshape(1,15)\n",
    "\n",
    "corr_mean_re=pd.DataFrame(data=corr_mean_re,columns=word_m.index)\n",
    "corr_mean_re.rename(columns=lambda x: x+'_mean', inplace=True)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.DataFrame()\n",
    "data['name']=[name]\n",
    "data['blurb']=[blurb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(data, open(\"wdata.dat\", \"wb\")) # wb = write binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open(\"wdata.dat\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# length of the name\n",
    "data['name_len'] = data.name.str.len()\n",
    "# if name contains a question mark\n",
    "data['name_is_question'] = (data.name.str[-1] == '?').astype(int)\n",
    "# if name contains an exclamation mark\n",
    "data['name_is_exclamation'] = (data.name.str[-1] == '!').astype(int)\n",
    "# if name is uppercase\n",
    "data['name_is_upper'] = data.name.str.isupper().astype(float)\n",
    "def count_non_character(row):\n",
    "    '''Number of non character in the sentence'''\n",
    "    return sum((0 if c.isalpha() else 1 for c in str(row)))\n",
    "# number of non character in the name\n",
    "data['name_non_character'] = data.name.apply(count_non_character)\n",
    "# number of words in the name\n",
    "data['name_number_of_word'] = data.name.apply(lambda x: len(str(x).split(' ')))\n",
    "# We generate new feature based on ratio between vowels and other alpha characters\n",
    "def countVowelstoLettersRatio(s):\n",
    "    '''Count ratio between vowels and letters'''\n",
    "    s = str(s)\n",
    "    count = 1  \n",
    "    vowels = 0\n",
    "    for i in s:\n",
    "        if i.isalpha():\n",
    "            count = count + 1\n",
    "            if i in 'aeiou':\n",
    "                vowels = vowels + 1\n",
    "    return ((vowels * 1.0) / count)\n",
    "\n",
    "# for each name calculate vowels ratio\n",
    "data['name_vowel_ratio'] = data.name.apply(countVowelstoLettersRatio)\n",
    "\n",
    "#blurb\n",
    "data['blurb_number_of_word'] = data.blurb.apply(lambda x: len(str(x).split(' ')))\n",
    "data['blurb_vowel_ratio'] = data.blurb.apply(lambda x: len(str(x).split(' ')))\n",
    "data['blurb_non_character'] = data.blurb.apply(count_non_character)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data=data.join(corr_t)\n",
    "data=data.join(corr_mean_re)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fantastic', 'new', 'table', 'design', 'very', 'trendy']\n",
      "Good words in campaign description [] 0\n",
      "Bad words in campaign description [] 0\n"
     ]
    }
   ],
   "source": [
    "blurb=re.sub(r'[^A-Za-z]', ' ', blurb)\n",
    "blurb=blurb.lower()\n",
    "blurb = blurb.split()\n",
    "\n",
    "gb=[]\n",
    "for i in s_blurb:\n",
    "    if i in blurb:\n",
    "        gb.append(i)\n",
    "bb=[]\n",
    "for i in f_blurb:\n",
    "    if i in blurb:\n",
    "        bb.append(i)\n",
    "ngb=len(gb)\n",
    "nbb=len(bb)\n",
    "data['goodblurb']=ngb\n",
    "data['badblurb']=nbb\n",
    "print (blurb)\n",
    "print('Good words in campaign description',gb,ngb)\n",
    "print('Bad words in campaign description',bb,nbb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['design', 'a', 'new', 'table']\n",
      "Good words in campaign name [] 0\n",
      "Bad words campaign name [] 0\n"
     ]
    }
   ],
   "source": [
    "name=re.sub(r'[^A-Za-z]', ' ', name)\n",
    "name=name.lower()\n",
    "name = name.split()\n",
    "\n",
    "gn=[]\n",
    "for i in s_words:\n",
    "    if i in name:\n",
    "        gn.append(i)\n",
    "bn=[]\n",
    "for i in f_words:\n",
    "    if i in name:\n",
    "        bn.append(i)\n",
    "ngn=len(gn)\n",
    "nbn=len(bn)\n",
    "data['goodname']=ngn\n",
    "data['badname']=nbn\n",
    "\n",
    "print (name)\n",
    "print('Good words in campaign name',gn,ngn)\n",
    "print('Bad words campaign name',bn,nbn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "score=pd.DataFrame()\n",
    "score['name_len']=((data['name_len']-data['name_len_mean'])/-data['name_len_mean'])*data['name_len_corr']\n",
    "score['name_is_question']=((data['name_is_question']-data['name_is_question_mean'])/data['name_is_question_mean'])*data['name_is_question_corr']\n",
    "score['name_is_exclamation']=((data['name_is_exclamation']-data['name_is_exclamation_mean'])/data['name_is_exclamation_mean'])*data['name_is_exclamation_corr']\n",
    "score['name_is_upper']=((data['name_is_upper']-data['name_is_upper_mean'])/data['name_is_upper_mean'])*data['name_is_upper_corr']\n",
    "score['name_non_character']=((data['name_non_character']-data['name_non_character_mean'])/data['name_non_character_mean'])*data['name_non_character_corr']\n",
    "score['name_number_of_word']=((data['name_len']-data['name_len_mean'])/data['name_len_mean'])*data['name_len_corr']\n",
    "score['name_vowel_ratio']=((data['name_vowel_ratio']-data['name_vowel_ratio_mean'])/data['name_vowel_ratio_mean'])*data['name_vowel_ratio_corr']\n",
    "score['blurb_vowel_ratio']=((data['blurb_vowel_ratio']-data['blurb_vowel_ratio_mean'])/data['blurb_vowel_ratio_mean'])*data['blurb_vowel_ratio_corr']\n",
    "score['blurb_non_character']=((data['blurb_non_character']-data['blurb_non_character_mean'])/data['blurb_non_character_mean'])*data['blurb_non_character_corr']\n",
    "score['goodname']=((data['goodname']-data['goodname_mean'])/data['goodname_mean'])*data['goodname_corr']\n",
    "score['badname']=((data['badname']-data['badname_mean'])/data['badname_mean'])*data['badname_corr']\n",
    "score['goodblurb']=((data['goodblurb']-data['goodblurb_mean'])/data['goodblurb_mean'])*data['goodblurb_corr']\n",
    "score['badblurb']=((data['badblurb']-data['badblurb_mean'])/data['badblurb_mean'])*data['badblurb_corr']\n",
    "score['Total_Score'] = score[score.columns].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mNAME improvments:\u001b[0m\n",
      "\u001b[1mGOOD words in this campaign NAME:\u001b[0m [] 0\n",
      "\u001b[1mBAD words in this campaign NAME:\u001b[0m [] 0\n",
      "\u001b[1mGOOD words for NAME in this category are:\u001b[0m ['david', 'magnetic', 'bowlmaker', 'eagle', 'good', 'whiskey', 'inspired', 'ltd', 'press', 'yarns', 'oils', 'walsh', 'quilt', 'razors', 'wick', 'n', 'oil', 'book', 'limited', 'fine', 'ceramic', 'pattern', 'exotic', 'holiday', 'accessories', 'bowls', 'cat', 'stationery', 'fire', 'turned', 'oak', 'bourbon', 'veterans', 'knitted', 'barrel', 'kids', 'trees', 'scottish', 'kiln', 'games', 'expansion', 'sustainable', 'leather', 'dyed', 'pen', 'ceramics', 'card', 'fiber', 'day', 'little', 'system', 'edition', 'real', 'black', 'ancient', 'writing']\n",
      "\n",
      "\n",
      "\u001b[1mDESCRIPTION improvments:\u001b[0m\n",
      "\u001b[1mGOOD words in this campaign DESCRIPTION:\u001b[0m [] 0\n",
      "\u001b[1mBAD words in this campaign DESCRIPTION:\u001b[0m [] 0\n",
      "\u001b[1mGOOD words for DESCRIPTION in this category are:\u001b[0m ['two', 'based', 'kickstarter', 'set', 'pottery', 'good', 'better', 'space', 'most', 'beard', 'favorite', 'patterns', 'domestic', 'book', 'working', 'limited', 'yarn', 'fine', 'her', 'through', 'raise', 'exotic', 'studio', 'support', 'collection', 'bowls', 'raising', 'perfect', 'paper', 'turned', 'brand', 'years', 'greeting', 'friends', 'barrels', 'woods', 'range', 'kiln', 'reclaimed', 'women', 'year', 'christmas', 'knitting', 'sustainable', 'dyed', 'turn', 'pen', 'fund', 'card', 'fiber', 'little', 'grow', 'funds', 'keep', 'woodworking']\n",
      "\n",
      "\n",
      "\u001b[1mTable Of Scores\u001b[0m\n",
      "                            0\n",
      "name_len             0.058804\n",
      "name_is_question    -0.006186\n",
      "name_is_exclamation -0.021803\n",
      "name_is_upper        0.000545\n",
      "name_non_character  -0.062660\n",
      "name_number_of_word -0.058804\n",
      "name_vowel_ratio    -0.000912\n",
      "blurb_vowel_ratio    0.000340\n",
      "blurb_non_character -0.008801\n",
      "goodname            -0.274968\n",
      "badname              0.148036\n",
      "goodblurb           -0.274609\n",
      "badblurb             0.214895\n",
      "Total_Score         -0.286122\n",
      "\n",
      "\n",
      "\u001b[1mTotal Score is:\u001b[0m -0.286121624547\n"
     ]
    }
   ],
   "source": [
    "print('\\033[1m' +'NAME improvments:'+'\\033[0m')\n",
    "print('\\033[1m' +'GOOD words in this campaign NAME:'+'\\033[0m',gn,ngn)\n",
    "print('\\033[1m' +'BAD words in this campaign NAME:'+'\\033[0m',bn,nbn)\n",
    "print('\\033[1m' +'GOOD words for NAME in this category are:'+'\\033[0m', s_words)\n",
    "\n",
    "print('\\n')\n",
    "print('\\033[1m' +'DESCRIPTION improvments:'+'\\033[0m')\n",
    "print('\\033[1m' +'GOOD words in this campaign DESCRIPTION:'+'\\033[0m',gb,ngb)\n",
    "print('\\033[1m' +'BAD words in this campaign DESCRIPTION:'+'\\033[0m',bb,nbb)\n",
    "print('\\033[1m' +'GOOD words for DESCRIPTION in this category are:'+'\\033[0m', s_blurb)\n",
    "\n",
    "print('\\n')\n",
    "print('\\033[1m' +'Table Of Scores'+'\\033[0m')\n",
    "print(score.T)\n",
    "print('\\n')\n",
    "print('\\033[1m' +'Total Score is:'+'\\033[0m', score['Total_Score'][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
